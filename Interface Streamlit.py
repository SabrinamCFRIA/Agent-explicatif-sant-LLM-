import requests
import streamlit as st
from datetime import datetime

API_URL = "http://localhost:1234/v1/chat/completions"
MODEL_NAME = "local-model"  # LM Studio accepte g√©n√©ralement ce nom

PROMPT_SYSTEME = """
Tu es un agent explicatif sp√©cialis√© dans l‚Äôintelligence artificielle appliqu√©e au secteur de la sant√©.

Ton r√¥le est d‚Äôexpliquer de mani√®re p√©dagogique et structur√©e des concepts li√©s aux mod√®les de langage de grande taille (LLM) et √† leurs usages en sant√©.

R√®gles strictes :
- Tu ne dois PAS fournir de diagnostic m√©dical.
- Tu ne dois PAS donner de conseil clinique.
- Tu ne dois PAS interpr√©ter de donn√©es r√©elles de patients.
- Tu dois adopter un ton neutre, prudent et informatif.
- Tu dois r√©pondre uniquement sous forme de points (bullet points).
- Tu dois toujours mentionner les limites et les risques.

Structure obligatoire de la r√©ponse :
1. D√©finition courte du concept
2. Pourquoi ce concept est important dans le secteur de la sant√©
3. Principaux risques ou limites
4. Exemple simple et fictif (non clinique)
5. Rappel que cet outil est une aide et non un syst√®me de d√©cision m√©dicale
""".strip()


def appeler_llm(question: str, temperature: float = 0.3, max_tokens: int = 500) -> str:
    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": PROMPT_SYSTEME},
            {"role": "user", "content": question}
        ],
        "temperature": temperature,
        "max_tokens": max_tokens,
    }
    r = requests.post(API_URL, json=payload, timeout=120)
    r.raise_for_status()
    data = r.json()
    return data["choices"][0]["message"]["content"]


st.set_page_config(page_title="Agent explicatif sant√© (LLM)", page_icon="ü©∫", layout="centered")

st.title("ü©∫ Agent explicatif sant√© (LLM)")
st.caption("Interface de d√©monstration ‚Äî outil informatif (pas de diagnostic).")

with st.expander("‚öôÔ∏è Param√®tres", expanded=False):
    temperature = st.slider("Temp√©rature (cr√©ativit√©)", 0.0, 1.0, 0.3, 0.05)
    max_tokens = st.slider("Longueur max (tokens)", 100, 1200, 500, 50)
    st.markdown("**API LM Studio :** " + API_URL)

st.markdown("### ‚ùì Question / concept √† expliquer")
question = st.text_area(
    "Exemples : hallucinations, biais, confidentialit√© des donn√©es patients, surconfiance dans l‚ÄôIA‚Ä¶",
    height=90,
    placeholder="Tape ici ta question‚Ä¶"
)

col1, col2 = st.columns([1, 1])
with col1:
    btn = st.button("üöÄ Expliquer", type="primary")
with col2:
    clear = st.button("üßπ Effacer l‚Äôhistorique")

if "historique" not in st.session_state:
    st.session_state.historique = []

if clear:
    st.session_state.historique = []
    st.rerun()

if btn:
    if not question.strip():
        st.warning("Merci de saisir une question.")
    else:
        with st.spinner("G√©n√©ration de l‚Äôexplication‚Ä¶"):
            try:
                reponse = appeler_llm(question, temperature=temperature, max_tokens=max_tokens)
                st.session_state.historique.insert(0, {
                    "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "question": question.strip(),
                    "reponse": reponse.strip()
                })
            except requests.exceptions.RequestException as e:
                st.error("Erreur de connexion √† LM Studio. V√©rifie que le serveur local est d√©marr√© (port 1234).")
                st.code(str(e))

st.markdown("---")
st.markdown("## üìå R√©sultats")

if len(st.session_state.historique) == 0:
    st.info("Aucun r√©sultat pour l‚Äôinstant. Pose une question puis clique sur **Expliquer**.")
else:
    for item in st.session_state.historique:
        with st.container():
            st.markdown(f"**üïí {item['date']}**")
            st.markdown(f"**Question :** {item['question']}")
            st.markdown("**R√©ponse :**")
            st.write(item["reponse"])
            st.markdown("---")

st.markdown("### ‚ö†Ô∏è Avertissement")
st.write(
    "Cet outil est con√ßu pour expliquer des concepts (IA/LLM) en contexte sant√©. "
    "Il ne fournit pas de diagnostic et ne remplace pas un avis m√©dical."
)
